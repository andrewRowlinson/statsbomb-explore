{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO CHANGE! Depending on where the open-data is located and where you want to save the resulting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open data folder is one folder down in the directory. To change if run elsewhere\n",
    "STATSBOMB_DATA = os.path.join('..','open-data')\n",
    "# save files in folder in current directory. To change if want to save elsewhere\n",
    "DATA_PATH = os.path.join(os.getcwd(),'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(PATH):\n",
    "    if os.path.isdir(PATH)==False: os.mkdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dir(DATA_PATH)\n",
    "make_dir(os.path.join(DATA_PATH,'events_raw'))\n",
    "make_dir(os.path.join(DATA_PATH,'related_events_raw'))\n",
    "make_dir(os.path.join(DATA_PATH,'short_freeze_raw'))\n",
    "make_dir(os.path.join(DATA_PATH,'tactics_raw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(STATSBOMB_DATA,'data')\n",
    "MATCH_PATH = glob.glob(os.path.join(DATA_PATH,'matches','**','*.json'),recursive=True)\n",
    "LINEUP_PATH = glob.glob(os.path.join(DATA_PATH,'lineups','**','*.json'),recursive=True)\n",
    "EVENT_PATH = glob.glob(os.path.join(DATA_PATH,'events','**','*.json'),recursive=True)\n",
    "COMPETITION_PATH = os.path.join(DATA_PATH,'competitions.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format competition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_competition = pd.read_json(COMPETITION_PATH,convert_dates=['match_updated','match_available'])\n",
    "df_competition.sort_values(['competition_id','season_id'],inplace=True)\n",
    "df_competition.reset_index(drop=True,inplace=True)\n",
    "print('Number of competitions in data:',len(df_competition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_competition.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_competition.to_feather(os.path.join(DATA_PATH,'competition'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of match files in data:',len(MATCH_PATH))\n",
    "match_list_dfs = [pd.read_json(file,convert_dates=['match_date','last_updated']) for file in MATCH_PATH]\n",
    "df_match = pd.concat(match_list_dfs,sort=False)\n",
    "print('Number of matches in data:',len(df_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dict_col(df,col):\n",
    "    '''function to split a dictionary column to seperate columns'''\n",
    "    # handle missings by filling with an empty dictionary\n",
    "    df[col] = df[col].apply(lambda x: {} if pd.isna(x) else x)\n",
    "    # split the non missings and change column names\n",
    "    df_temp_cols = pd.io.json.json_normalize(df[col]).set_index(df.index)\n",
    "    col_names = df_temp_cols.columns\n",
    "    col_names = [(col+'_'+c).replace('.','_') for c in col_names]\n",
    "    df[col_names] = df_temp_cols\n",
    "    # drop old column\n",
    "    df.drop(col,axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the columns that are still dictionary columns and add them as seperate cols to the dataframe\n",
    "dictionary_columns = ['competition','season','home_team','away_team','metadata','competition_stage',\n",
    "                      'stadium','referee']\n",
    "for col in dictionary_columns:\n",
    "    df_match = split_dict_col(df_match,col)\n",
    "df_match['kick_off'] = pd.to_datetime(df_match.match_date.astype(str) +' '+ df_match.kick_off)\n",
    "# rename some of the id columns with repeated names, as we added the column name infront of the new cols\n",
    "df_match.rename({'season_season_id':'season_id',\n",
    "                 'season_season_name':'season_name',\n",
    "                 'competition_competition_id':'competition_id',\n",
    "                 'home_team_home_team_id':'home_team_id',\n",
    "                 'away_team_away_team_id':'away_team_id',\n",
    "                 'competition_competition_name':'competition_name',           \n",
    "                 'home_team_home_team_name':'home_team_name',\n",
    "                 'home_team_home_team_gender':'home_team_gender',\n",
    "                 'home_team_home_team_group':'home_team_group',\n",
    "                 'away_team_away_team_name':'away_team_name',\n",
    "                 'away_team_away_team_gender':'away_team_gender',\n",
    "                 'away_team_away_team_group':'away_team_group'},axis=1,inplace=True)\n",
    "# drop one gender column as always equal to the other\n",
    "# drop match status as always available\n",
    "df_match.drop(['away_team_gender','match_status'],axis=1,inplace=True)\n",
    "df_match.rename({'home_team_gender':'competition_gender'},axis=1,inplace=True)\n",
    "# manager is a list (len=1) containing a dictionary so lets split into columns\n",
    "df_match['home_team_managers'] = df_match.home_team_managers.str[0]\n",
    "df_match = split_dict_col(df_match,'home_team_managers')\n",
    "df_match['away_team_managers'] = df_match.away_team_managers.str[0]\n",
    "df_match = split_dict_col(df_match,'away_team_managers')\n",
    "df_match['home_team_managers_dob'] = pd.to_datetime(df_match['home_team_managers_dob'])\n",
    "df_match['away_team_managers_dob'] = pd.to_datetime(df_match['away_team_managers_dob'])\n",
    "for col in ['competition_id','season_id','home_team_id','competition_stage_id']:\n",
    "    df_match[col] = df_match[col].astype(np.int64)\n",
    "# sort and reset index: ready for exporting to feather\n",
    "df_match.sort_values('kick_off',inplace=True)\n",
    "df_match.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match.to_feather(os.path.join(DATA_PATH,'match'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format lineup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of lineup files in data:',len(LINEUP_PATH))\n",
    "# read as dataframe can't use list comprehension to read files as need to create the match_id from the file name\n",
    "lineup_list_dfs = []\n",
    "for file in LINEUP_PATH:\n",
    "    df_temp = pd.read_json(file)\n",
    "    df_temp['match_id'] = os.path.basename(file[:-5])\n",
    "    lineup_list_dfs.append(df_temp)\n",
    "df_lineup = pd.concat(lineup_list_dfs,sort=False)\n",
    "df_lineup.reset_index(inplace=True,drop=True)\n",
    "# each line has a column named player that contains a list of dictionaries\n",
    "# we split into seperate columns and then create a new row for each player using melt\n",
    "df_lineup_players = df_lineup.lineup.apply(pd.Series)\n",
    "df_lineup = df_lineup.merge(df_lineup_players,left_index=True,right_index=True)\n",
    "df_lineup.drop('lineup',axis=1,inplace=True)\n",
    "df_lineup = df_lineup.melt(id_vars = ['team_id','team_name','match_id'], value_name = 'player')\n",
    "df_lineup.drop('variable',axis=1,inplace=True)\n",
    "df_lineup = df_lineup[df_lineup.player.notnull()].copy()\n",
    "df_lineup = split_dict_col(df_lineup,'player')\n",
    "# rename columns with repeated words\n",
    "cols = df_lineup.columns\n",
    "cols = [col[7:] if col[:6]=='player' else col for col in cols]\n",
    "df_lineup.columns = cols\n",
    "# turn ids to integers if no missings\n",
    "df_lineup['match_id'] = df_lineup.match_id.astype(np.int64)\n",
    "df_lineup['player_id'] = df_lineup.player_id.astype(np.int64)\n",
    "# sort and reset index: ready for exporting to feather\n",
    "df_lineup.sort_values('player_id',inplace=True)\n",
    "df_lineup.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lineup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lineup.to_feather(os.path.join(DATA_PATH,'lineup'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format event data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of event files in data:',len(EVENT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_dfs(PATH):\n",
    "    df = pd.read_json(PATH,convert_dates=['timestamp'],encoding='utf-8')\n",
    "    \n",
    "    # get match id\n",
    "    match_id = os.path.basename(EVENT_PATH[0])[:-5]\n",
    "    \n",
    "    # loop through the columns that are still dictionary columns and add them as seperate cols to the dataframe\n",
    "    # these are nested dataframes in the docs - although dribbled_past/ pressure isn't needed here?\n",
    "    # also some others are needed: type, possession_team, play_pattern, team, tactics, player, pposition\n",
    "    dictionary_columns = ['50_50','bad_behaviour','ball_receipt','ball_recovery','block','carry',\n",
    "                          'clearance','dribble','duel','foul_committed','foul_won','goalkeeper',\n",
    "                          'half_end','half_start','injury_stoppage','interception',\n",
    "                          'miscontrol','pass','play_pattern','player','player_off','position',\n",
    "                          'possession_team','shot','substitution','tactics','team','type',] \n",
    "    for col in dictionary_columns:\n",
    "        if col in df.columns:\n",
    "            df = split_dict_col(df,col)\n",
    "    \n",
    "    # sort and reset index: ready for exporting to feather\n",
    "    df.sort_values(['minute','second','timestamp','possession'],inplace=True)\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    # split location info to x, y, z and drop old columns\n",
    "    df[['x','y']] = df.location.apply(pd.Series)\n",
    "    df[['pass_end_x','pass_end_y']] = df.pass_end_location.apply(pd.Series)\n",
    "    df[['carry_end_x','carry_end_y']] = df.carry_end_location.apply(pd.Series)\n",
    "    df[['shot_end_x','shot_end_y','shot_end_z']] = df.shot_end_location.apply(pd.Series)\n",
    "    df[['goalkeeper_end_x','goalkeeper_end_y']] = df.goalkeeper_end_location.apply(pd.Series)\n",
    "    df.drop(['location','pass_end_location','carry_end_location',\n",
    "             'shot_end_location','goalkeeper_end_location'],axis=1,inplace=True)\n",
    "    \n",
    "    # replace weird * character in the type_name for ball receipt\n",
    "    df['type_name'] = df['type_name'].replace({'Ball Receipt*':'Ball Receipt'})\n",
    "    \n",
    "    # create a related events dataframe\n",
    "    df_related_events = df.loc[df.related_events.notnull(),['id','related_events']].copy()\n",
    "    df_related_events.set_index('id',inplace=True)\n",
    "    df_related_events = df_related_events.related_events.apply(pd.Series)\n",
    "    df_related_events.reset_index(inplace=True)\n",
    "    df_related_events = df_related_events.melt(id_vars ='id', value_name = 'related_event',\n",
    "                                               var_name='event_related_id')\n",
    "    df_related_events['event_related_id'] = df_related_events.event_related_id + 1\n",
    "    df_related_events = df_related_events[df_related_events.related_event.notnull()].copy()\n",
    "    df_related_events.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    \n",
    "    # create a shot freeze frame dataframe\n",
    "    df_shot_freeze = df.loc[df.shot_freeze_frame.notnull(),['id','shot_freeze_frame']]\n",
    "    df_shot_freeze.set_index('id',inplace=True)\n",
    "    df_shot_freeze = df_shot_freeze.shot_freeze_frame.apply(pd.Series)\n",
    "    df_shot_freeze.reset_index(inplace=True)\n",
    "    df_shot_freeze = df_shot_freeze.melt(id_vars ='id', value_name = 'player',var_name='event_freeze_id')\n",
    "    df_shot_freeze['event_freeze_id'] = df_shot_freeze.event_freeze_id + 1\n",
    "    df_shot_freeze = df_shot_freeze[df_shot_freeze.player.notnull()].copy()\n",
    "    df_shot_freeze = split_dict_col(df_shot_freeze,'player')\n",
    "    df_shot_freeze[['x','y']] = df_shot_freeze.player_location.apply(pd.Series)\n",
    "    df_shot_freeze.drop('player_location',axis=1,inplace=True)\n",
    "    df_shot_freeze.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    df_tactics_lineup = df.loc[df.tactics_lineup.notnull(),['id','tactics_lineup']].copy()\n",
    "    df_tactics_lineup.set_index('id',inplace=True)\n",
    "    df_tactics_lineup = df_tactics_lineup.tactics_lineup.apply(pd.Series)\n",
    "    df_tactics_lineup.reset_index(inplace=True)\n",
    "    df_tactics_lineup = df_tactics_lineup.melt(id_vars ='id', value_name = 'player',var_name='event_tactics_id')\n",
    "    df_tactics_lineup['event_tactics_id'] = df_tactics_lineup.event_tactics_id+ 1\n",
    "    df_tactics_lineup = df_tactics_lineup[df_tactics_lineup.player.notnull()].copy()\n",
    "    df_tactics_lineup = split_dict_col(df_tactics_lineup,'player')\n",
    "    df_tactics_lineup.sort_values(['id','event_tactics_id'],inplace=True)\n",
    "    df_tactics_lineup.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    # drop columns stored as a seperate table \n",
    "    df.drop(['related_events','shot_freeze_frame','tactics_lineup'],axis=1,inplace=True)\n",
    "    \n",
    "    # add match id to dataframes\n",
    "    df['match_id'] = match_id\n",
    "    df_related_events['match_id'] = match_id\n",
    "    df_shot_freeze['match_id'] = match_id    \n",
    "    df_tactics_lineup['match_id'] = match_id\n",
    "    \n",
    "    return df, df_related_events, df_shot_freeze, df_tactics_lineup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event, df_related_events, df_shot_freeze, df_tactics_lineup = create_event_dfs(EVENT_PATH[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event.to_feather(os.path.join(DATA_PATH,'events_raw',os.path.basename(EVENT_PATH[0][:-5])))\n",
    "df_related_events.to_feather(os.path.join(DATA_PATH,'related_events_raw',os.path.basename(EVENT_PATH[0][:-5])))\n",
    "df_shot_freeze.to_feather(os.path.join(DATA_PATH,'short_freeze_raw',os.path.basename(EVENT_PATH[0][:-5])))\n",
    "df_tactics_lineup.to_feather(os.path.join(DATA_PATH,'tactics_raw',os.path.basename(EVENT_PATH[0][:-5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !! TO DO SIMPLIFY THE DATAFRAME CREATION AS A LOT OF DUPLICATED CODE IN ABOVE FUNCTION. ALSO USED ABOVE TOO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! TO DO individually and save as feather in correct folder. Check what files already feather and only do new ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the raw dataframes and save as a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shot_freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tactics_lineup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !! TO DO save as seperate tables\n",
    "# related_events\n",
    "# shot freeze frame\n",
    "# tactics lineup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = df_event.columns\n",
    "#cols[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if a match is missing any metadata or vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineup to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(LINEUP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(EVENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
